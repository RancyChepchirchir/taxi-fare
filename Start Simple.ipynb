{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction: Taxi Fare Prediction\n",
    "\n",
    "Welcome to another Kaggle challenge. In this contest, the aim is to predict the fare of a taxi ride given the starting time, the starting and ending latitude / longitude, and the number of passengers. This is a __supervised regression__ machine learning task.\n",
    "\n",
    "In this notebook, I'll provide you with a solid foundation and leave you with the challenge to better the score. Although the dataset is large, this is an approachable problem and as usual with Kaggle competitions, provides realistic practice for building a machine learning solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas and numpy for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "# Set random seed \n",
    "RSEED = 100\n",
    "\n",
    "# Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['font.size'] = 18\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in 5 million rows and examine data\n",
    "\n",
    "Throughout this notebook, we will work with only 5 million rows (out of 55 million). The first point for improvement might therefore be to use more data!\n",
    "\n",
    "* __Potential improvement 1: use more data__\n",
    "\n",
    "First we'll remove any `nan` (observations with missing entries). We will also drop the `key` since it is a unique identifier and does not tell us anything about the taxi trip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('input/train.csv', nrows = 5_000_000, \n",
    "                   parse_dates = ['pickup_datetime']).drop(columns = 'key')\n",
    "\n",
    "# Remove na\n",
    "data = data.dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe Data\n",
    "\n",
    "An effective method for catching outliers and anomalies is to find the summary statistics for the data using the `.describe()` method. I like to concentrate on the maxes and the minimums."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right away we can see there are a number of outliers in the `latitude` and `longitude` columns as well as at least one suspicious entry in the `passenger_count`. The target varible, `fare_amount` seems to have both negative values (unexpected) and extreme values (not so unexpected)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the Target Variable\n",
    "\n",
    "For a first graphical exploration, we can look at the distribution of the `fare_amount`, the target variable we want to train a model to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 6))\n",
    "sns.distplot(data['fare_amount']);\n",
    "plt.title('Distribution of Fare');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"There are {len(data[data['fare_amount'] < 0])} negative fares.\")\n",
    "print(f\"There are {len(data[data['fare_amount'] == 0])} $0 fares.\")\n",
    "print(f\"There are {len(data[data['fare_amount'] > 100])} fares greater than $100.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Outliers\n",
    "\n",
    "I'm going to remove any fares less than or equal to \\$0 and also any fares greater than \\$100. I'll justify this based on the limited number of fares outside these bounds, but it might be possible that including these values helps the model! I'd encourage you to try different values and see which works best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['fare_amount'].between(left = 0, right = 100)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For visualization purposes, I'll create a binned version of the fare. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin the fare and convert to string\n",
    "data['fare-bin'] = pd.cut(data['fare_amount'], bins = list(range(0, 50, 5))).astype(str)\n",
    "\n",
    "# Uppermost bin\n",
    "data.loc[data['fare-bin'] == 'nan', 'fare-bin'] = '[45+]'\n",
    "\n",
    "# Adjust bin so the sorting is correct\n",
    "data.loc[data['fare-bin'] == '(5, 10]', 'fare-bin'] = '(05, 10]'\n",
    "\n",
    "# Bar plot of value counts\n",
    "data['fare-bin'].value_counts().sort_index().plot.bar(color = 'b', edgecolor = 'k');\n",
    "plt.title('Fare Binned');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also remove observations based on outliers in other columns. First we'll make a graph of the passenger counts which seemed to have some suspicious values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['passenger_count'].value_counts().plot.bar(color = 'b', edgecolor = 'k');\n",
    "plt.title('Passenger Counts'); plt.xlabel('Number of Passengers'); plt.ylabel('Count');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this graph, we'll remove any passenger counts greater than 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[data['passenger_count'] < 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the `latitude` and `longitude` columns, we can use statistics as well as our intuition for removing outliers. Here I'll find the 2.5% and 97.5% percentile values in each column and keep only measurements close to that range. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Initial Observations: {data.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude']:\n",
    "    print(f'{col.capitalize():17}: 2.5% = {round(np.percentile(data[col], 2.5), 2)} \\t 97.5% = {round(np.percentile(data[col], 97.5), 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these values, we can remove outliers. Here is another potential point for improvement:\n",
    "\n",
    "* __Potential improvement 2: find a better way to remove outliers.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove latitude and longtiude outliers\n",
    "data = data.loc[(data['pickup_latitude'] > 40) & (data['pickup_latitude'] < 42)]\n",
    "data = data.loc[(data['pickup_longitude'] > -75) & (data['pickup_longitude'] < -72)]\n",
    "data = data.loc[(data['dropoff_latitude'] > 40) & (data['dropoff_latitude'] < 42)]\n",
    "data = data.loc[(data['dropoff_longitude'] > -75) & (data['dropoff_longitude'] < -72)]\n",
    "\n",
    "print(f'New number of observations: {data.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can graph the `latitude` and `longitude` columns to see the distribution. We'll just sample 10000 values so the plot doesn't take too long to generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize = (20, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "sns.regplot('pickup_longitude', 'pickup_latitude', fit_reg = False, \n",
    "            data = data.sample(10000, random_state = RSEED), ax = axes[0]);\n",
    "sns.regplot('dropoff_longitude', 'dropoff_latitude', fit_reg = False, \n",
    "            data = data.sample(10000, random_state = RSEED), ax = axes[1]);\n",
    "# axes[1].set_xlim((-75, -73))\n",
    "# axes[1].set_ylim((-75, -73));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could plot the pickup and dropoff on top of a map of New York. The following code is taken directly from https://www.kaggle.com/breemen/nyc-taxi-fare-data-exploration by Kaggle user [breeman](https://www.kaggle.com/breemen). All credit goes to him and please check out the rest of his kernel for more excellent work! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image of NYC map\n",
    "BB = (-74.5, -72.8, 40.5, 41.8)\n",
    "nyc_map = plt.imread('https://aiblog.nl/download/nyc_-74.5_-72.8_40.5_41.8.png')\n",
    "\n",
    "# load extra image to zoom in on NYC\n",
    "BB_zoom = (-74.3, -73.7, 40.5, 40.9)\n",
    "nyc_map_zoom = plt.imread('https://aiblog.nl/download/nyc_-74.3_-73.7_40.5_40.9.png')\n",
    "\n",
    "# this function will be used more often to plot data on the NYC map\n",
    "def plot_on_map(df, BB, nyc_map, s=10, alpha=0.2):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(18, 16))\n",
    "    axs[0].scatter(df.pickup_longitude, df.pickup_latitude, zorder=1, alpha=alpha, c='r', s=s)\n",
    "    axs[0].set_xlim((BB[0], BB[1]))\n",
    "    axs[0].set_ylim((BB[2], BB[3]))\n",
    "    axs[0].set_title('Pickup locations')\n",
    "    axs[0].imshow(nyc_map, zorder=0, extent=BB)\n",
    "\n",
    "    axs[1].scatter(df.dropoff_longitude, df.dropoff_latitude, zorder=1, alpha=alpha, c='r', s=s)\n",
    "    axs[1].set_xlim((BB[0], BB[1]))\n",
    "    axs[1].set_ylim((BB[2], BB[3]))\n",
    "    axs[1].set_title('Dropoff locations')\n",
    "    axs[1].imshow(nyc_map, zorder=0, extent=BB)\n",
    "    \n",
    "# plot training data on map zoomed in\n",
    "plot_on_map(data, BB_zoom, nyc_map_zoom, s=0.05, alpha=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "Feature engineering is the process of creating features - predictor variables - out of a dataset. __Feature engineering is the most important step of the machine learning pipeline.__ A model can only learn from the features it is given, and properly constructing features will determine how well your model performs.\n",
    "\n",
    "As a simple first step of feature engineering, we can find the absolute value of the difference in latitude and longitude between the `pickup` and `dropoff`. While this does not represent an actual distance (we would have to convert coordinate systems), it can be used as a relative comparison of the distances of taxi rides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Absolute difference in latitude and longitude\n",
    "data['abs_lat_diff'] = (data['dropoff_latitude'] - data['pickup_latitude']).abs()\n",
    "data['abs_lon_diff'] = (data['dropoff_longitude'] - data['pickup_longitude']).abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot('abs_lat_diff', 'abs_lon_diff', fit_reg = False, data = data.sample(10000, random_state=RSEED));\n",
    "plt.title('Absolute latitude difference vs Absolute longitude difference');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There do seem to be a few outliers, but I'll leave those in for now. We might also want to take a look if there are any observations where both the absolute differences are 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_diff = data[(data['abs_lat_diff'] == 0) & (data['abs_lon_diff'] == 0)]\n",
    "no_diff.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there are 52,000 rides where the absolute latitude and longitude does not change! That seems a little strange. This might be a point worth following up! \n",
    "\n",
    "Let's remake the plot above colored by the fare bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot('abs_lat_diff', 'abs_lon_diff', hue = 'fare-bin', size = 8,\n",
    "           fit_reg = False, data = data.sample(10000, random_state=RSEED));\n",
    "plt.title('Absolute latitude difference vs Absolute longitude difference');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot('abs_lat_diff', 'abs_lon_diff', hue = 'fare-bin', size = 8,\n",
    "           fit_reg = False, data = data.sample(10000, random_state=RSEED));\n",
    "\n",
    "plt.xlim((-0.01, .25)); plt.ylim((-0.01, .25))\n",
    "plt.title('Absolute latitude difference vs Absolute longitude difference');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does seem that the rides with a larger absolute difference in both longitude and latitude tend to cost more. To capture both differences in a single variable, we can add up the two differences and also find the square root of the sum of distances squared. The former feature would be called the Manhattan distance - or l1 norm - and the latter is called the Euclidean distance - or l2 norm. Both of these distances are specific examples of the general Minkowski distance.\n",
    "\n",
    "### Minkowski Distance\n",
    "\n",
    "The [Minkowski Distance](https://en.wikipedia.org/wiki/Minkowski_distance) between two points is expressed as:\n",
    "\n",
    "$${\\displaystyle D\\left(X,Y\\right)=\\left(\\sum _{i=1}^{n}|x_{i}-y_{i}|^{p}\\right)^{1/p}}$$\n",
    "\n",
    "if p = 1, then this is the Manhattan distance and if p = 2 this is the Euclidean distance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minkowski_distance(x1, x2, y1, y2, p):\n",
    "    return ((abs(x2 - x1) ** p) + (abs(y2 - y1)) ** p) ** (1 / p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example of the Manhattan Distance which is simply the sum of differences in each dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minkowski_distance(0, 3, 0, 4, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the same as a Euclidean distance which is the length of a straight line connecting the points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minkowski_distance(0, 3, 0, 4, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply this function to the latitude and longitudes. Again, this does not represent an absolute distance because we would need to convert coordinate systems. However, these features are useful as _relative_ comparisons between rides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['manhattan'] = minkowski_distance(data['pickup_longitude'], data['dropoff_longitude'],\n",
    "                                       data['pickup_latitude'], data['dropoff_latitude'], 1)\n",
    "\n",
    "# Calculate distribution by each fare bin\n",
    "plt.figure(figsize = (12, 6))\n",
    "for f, grouped in data.groupby('fare-bin'):\n",
    "    sns.kdeplot(grouped['manhattan'], label = f'{f}');\n",
    "\n",
    "plt.xlabel('degrees'); plt.ylabel('density')\n",
    "plt.title('Manhattan Distance by Fare Amount');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['euclidean'] = minkowski_distance(data['pickup_longitude'], data['dropoff_longitude'],\n",
    "                                       data['pickup_latitude'], data['dropoff_latitude'], 2)\n",
    "\n",
    "# Calculate distribution by each fare bin\n",
    "plt.figure(figsize = (12, 6))\n",
    "for f, grouped in data.groupby('fare-bin'):\n",
    "    sns.kdeplot(grouped['euclidean'], label = f'{f}');\n",
    "\n",
    "plt.xlabel('degrees'); plt.ylabel('density')\n",
    "plt.title('Euclidean Distance by Fare Amount');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These features do seem to have some differences between the different fare amounts, so they might be helpful in predicting the fare. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('fare-bin')['euclidean'].agg(['mean', 'count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another plot we can make is the passenger count distribution colored by the fare bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 6))\n",
    "\n",
    "for p, grouped in data.groupby('passenger_count'):\n",
    "    sns.kdeplot(grouped['fare_amount'], label = f'{p} passengers')\n",
    "    \n",
    "plt.xlabel('Fare Amount'); plt.ylabel('Density')\n",
    "plt.title('Distribution of Fare Amount by Number of Passengers');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There does not appear to be much difference between the number of passengers. To get a more accurate picture, we can calculate the actual stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('passenger_count')['fare_amount'].agg(['mean', 'count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nope! No real difference in fare between the number of passengers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in test data and create same features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we forget, we need to read in the test data and create the same features. We can't exclude any of the test data based on outliers, and we also shouldn't use the test data for filtering outliers in the training data. The test data should ideally only be used a single time, to test the performance of a trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the test data, we need to save the `key` column for making submissions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('input/test.csv')\n",
    "\n",
    "test['abs_lat_diff'] = (test['dropoff_latitude'] - test['pickup_latitude']).abs()\n",
    "test['abs_lon_diff'] = (test['dropoff_longitude'] - test['pickup_longitude']).abs()\n",
    "\n",
    "# Save the id for submission\n",
    "test_id = list(test.pop('key'))\n",
    "\n",
    "test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No fare information here! It's our job to predict the fare for each test ride."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['manhattan'] = minkowski_distance(test['pickup_longitude'], test['dropoff_longitude'],\n",
    "                                       test['pickup_latitude'], test['dropoff_latitude'], 1)\n",
    "\n",
    "test['euclidean'] = minkowski_distance(test['pickup_longitude'], test['dropoff_longitude'],\n",
    "                                       test['pickup_latitude'], test['dropoff_latitude'], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Distance between points using Haversine distance\n",
    "\n",
    "Another feature engineering step to use is calculating the distance (in km) between the pickup and dropoff using the [Haversine distance](https://en.wikipedia.org/wiki/Haversine_formula). This is the distance along a line drawn on the surface of the Earth connecting the two points and takes into account the fact that the Earth is a sphere (or so I'm told). It's not the best measure because the taxis do not travel along lines, but it's probably more accurate than the Manhattan and Euclidean distances made from the absolute latitude and longitude difference. The Manhattan and Euclidean distances are relative and do not take into account the spherical shape of the Earth.\n",
    "\n",
    "The formula for Haversine distance is:\n",
    "\n",
    "$${\\displaystyle =2r\\arcsin \\left({\\sqrt {\\sin ^{2}\\left({\\frac {\\varphi _{2}-\\varphi _{1}}{2}}\\right)+\\cos(\\varphi _{1})\\cos(\\varphi _{2})\\sin ^{2}\\left({\\frac {\\lambda _{2}-\\lambda _{1}}{2}}\\right)}}\\right)}$$\n",
    "\n",
    "where r is the radius of the Earth. The end units will be in km."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Radius of hte earth in kilometers\n",
    "R = 6378\n",
    "\n",
    "def haversine_np(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points\n",
    "    on the earth (specified in decimal degrees)\n",
    "\n",
    "    All args must be of equal length.    \n",
    "    \n",
    "    source: https://stackoverflow.com/a/29546836\n",
    "\n",
    "    \"\"\"\n",
    "    # Convert latitude and longitude to radians\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # Find the differences\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    # Apply the formula \n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
    "    # Calculate the angle (in radians)\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    # Convert to kilometers\n",
    "    km = R * c\n",
    "    \n",
    "    return km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['haversine'] =  haversine_np(data['pickup_longitude'], data['pickup_latitude'],\n",
    "                         data['dropoff_longitude'], data['dropoff_latitude']) \n",
    "\n",
    "test['haversine'] = haversine_np(test['pickup_longitude'], test['pickup_latitude'],\n",
    "                         test['dropoff_longitude'], test['dropoff_latitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = data.sample(100000, random_state=RSEED)\n",
    "\n",
    "plt.figure(figsize = (10, 6))\n",
    "\n",
    "for f, grouped_data in subset.groupby('fare-bin'):\n",
    "    sns.kdeplot(grouped_data['haversine'], label = f'{f}')\n",
    "    \n",
    "plt.title('Distribution of Haversine Distance by Fare Bin');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does seem there is a significant difference here! The larger haversine distances tend to have larger fares as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('fare-bin')['haversine'].agg(['mean', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('fare-bin')['haversine'].mean().sort_index().plot.bar(color = 'g');\n",
    "plt.title('Average Haversine Distance by Fare Amount');\n",
    "plt.ylabel('Mean Haversine Distance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(test['haversine']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test distribution seems to be similar to the training distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "Now that we have built a few potentially useful features, we can use them for machine learning: training an algorithm to predict the target from the features. We'll start off with a basic model only using a few features and then move on to more complex models with more features.\n",
    "\n",
    "## First Model: Linear Regression\n",
    "\n",
    "The first model we'll make is a simple linear regression using 3 features: the `abs_lat_diff`, `abs_lon_diff`, and `passenger_count`. This is meant to serve as a baseline for us to beat.\n",
    "\n",
    "It's good to start with a simple model because it will give you a baseline. Also, if a simple model works well enough, then there may be no need for more complex models. If a linear regression will get the job done, then you don't need a neural network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Training and Validation Set\n",
    "\n",
    "We'll want to create a training and separate validation set to assess our model. Ideally, we only use the test set once, to evaluate the final model. We can a the validation set with 1 million observations to estimate our performance.\n",
    "\n",
    "We __stratify__ the split using the `fare-bin`. This ensures that the training and validation set have the same distribution of fare bins. This is important for imbalanced classification problems, but it can also be useful for regression problems so we don't end up with a lot of outliers in terms of the target in either the validation or training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(data, np.array(data['fare_amount']), \n",
    "                                                      stratify = data['fare-bin'],\n",
    "                                                      random_state = RSEED, test_size = 1_000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with Simple Features\n",
    "\n",
    "We can train the linear regression using three features. The benefit of the linear regression is that it's interpretable: we can inspect the coefficients and intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train[['abs_lat_diff', 'abs_lon_diff', 'passenger_count']], y_train)\n",
    "\n",
    "print('Intercept', round(lr.intercept_, 4))\n",
    "print('abs_lat_diff coef: ', round(lr.coef_[0], 4), \n",
    "      'abs_lon_diff coef:', round(lr.coef_[1], 4),\n",
    "      'passenger_count coef:', round(lr.coef_[2], 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In all cases, the coefficient is positive, indicating a larger value of the variable corresponds to a larger fare according to the model. The `intercept` indicates the fare that would be predicted if there is no latitude or longitude difference and the passenger count is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score Model\n",
    "\n",
    "Here we use the validation set for assessing the model. We'll use two metrics:\n",
    "\n",
    "* __Root mean squared error__: the metric used by the competition\n",
    "* __Mean absolute percentage error__: the average percentage error of the predictions\n",
    "\n",
    "I like using the mean absolute percentage error (MAPE) because it's often more interpretable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category = RuntimeWarning)\n",
    "\n",
    "def metrics(train_pred, valid_pred, y_train, y_valid):\n",
    "    \"\"\"Calculate metrics:\n",
    "       Root mean squared error and mean absolute percentage error\"\"\"\n",
    "    \n",
    "    # Root mean squared error\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, train_pred))\n",
    "    valid_rmse = np.sqrt(mean_squared_error(y_valid, valid_pred))\n",
    "    \n",
    "    # Calculate absolute percentage error\n",
    "    train_ape = abs((y_train - train_pred) / y_train)\n",
    "    valid_ape = abs((y_valid - valid_pred) / y_valid)\n",
    "    \n",
    "    # Account for y values of 0\n",
    "    train_ape[train_ape == np.inf] = 0\n",
    "    train_ape[train_ape == -np.inf] = 0\n",
    "    valid_ape[valid_ape == np.inf] = 0\n",
    "    valid_ape[valid_ape == -np.inf] = 0\n",
    "    \n",
    "    train_mape = 100 * np.mean(train_ape)\n",
    "    valid_mape = 100 * np.mean(valid_ape)\n",
    "    \n",
    "    return train_rmse, valid_rmse, train_mape, valid_mape\n",
    "\n",
    "def evaluate(model, features, X_train, X_valid, y_train, y_valid):\n",
    "    \"\"\"Mean absolute percentage error\"\"\"\n",
    "    \n",
    "    # Make predictions\n",
    "    train_pred = model.predict(X_train[features])\n",
    "    valid_pred = model.predict(X_valid[features])\n",
    "    \n",
    "    # Get metrics\n",
    "    train_rmse, valid_rmse, train_mape, valid_mape = metrics(train_pred, valid_pred,\n",
    "                                                             y_train, y_valid)\n",
    "    \n",
    "    print(f'Training:   rmse = {round(train_rmse, 2)} \\t mape = {round(train_mape, 2)}')\n",
    "    print(f'Validation: rmse = {round(valid_rmse, 2)} \\t mape = {round(valid_mape, 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(lr, ['abs_lat_diff', 'abs_lon_diff', 'passenger_count'], \n",
    "        X_train, X_valid, y_train, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Baseline\n",
    "\n",
    "To make sure that machine learning is even applicable to the task, we should compare these predictions to a naive guess. For a regression task, this can be as simple as the average value of the target in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = y_train.mean()\n",
    "train_preds = [train_mean for _ in range(len(y_train))]\n",
    "valid_preds = [train_mean for _ in range(len(y_valid))]\n",
    "\n",
    "tr, vr, tm, vm = metrics(train_preds, valid_preds, y_train, y_valid)\n",
    "\n",
    "print(f'Baseline Training:   rmse = {round(tr, 2)} \\t mape = {round(tm, 2)}')\n",
    "print(f'Baseline Validation: rmse = {round(vr, 2)} \\t mape = {round(vm, 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the naive baseline, our machine learning solution is effective! We are able to reduce the percentage error by about half and generate much better predictions than using no machine learning. This should give us confidence we are on the right track.\n",
    "\n",
    "### Make a submission\n",
    "\n",
    "In order to make a submission to Kaggle, we have to make predictions on the test data. Below we make the predictions and save them to a csv file in the format specified by the competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = lr.predict(test[['abs_lat_diff', 'abs_lon_diff', 'passenger_count']])\n",
    "\n",
    "sub = pd.DataFrame({'key': test_id, 'fare_amount': preds})\n",
    "sub.to_csv('sub_lr_simple.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check, we can plot the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(sub['fare_amount'])\n",
    "plt.title('Predicted Fare Amount');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted distribution appears reasonable. Because the competition uses root mean squared error as the metric, any predictions that are far off will have an outsized effect on the error. Let's look at predictions that were greater than \\$100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[sub[sub['fare_amount'] > 100].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub[sub['fare_amount'] > 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These three predictions that are all over \\$100 don't appear to be completely shocking given the `abs_lat_diff` and `abs_lon_diff`. We'll have to take a look at these predictions for other models and see if they agree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_over_100 = list(sub[sub['fare_amount'] > 100].index)\n",
    "sub['fare_amount'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use More Features\n",
    "\n",
    "While the first model scored well relative to the baseline, there is much room for improvement. As a first step, let's use one of the other features we created, the `haversine` distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train[['haversine', 'abs_lat_diff', 'abs_lon_diff', 'passenger_count']], y_train)\n",
    "\n",
    "evaluate(lr, ['haversine', 'abs_lat_diff', 'abs_lon_diff', 'passenger_count'], \n",
    "         X_train, X_valid, y_train, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr.intercept_)\n",
    "print(lr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this one more feature improved our score slightly. Here's another chance for improvement using the same model:\n",
    "\n",
    "* __Potential Improvement 3: find the optimal set of features using the simple linear regression model__\n",
    "\n",
    "One thing we do want to be careful about is highly correlated, known as collinear features. These can decrease the generalization performance of the model and lead to less interpretable models. Many of our features are already highly correlated as shown in the heatmap below. This plots the Pearson Correlation Coefficient for each pair of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = data.corr()\n",
    "\n",
    "plt.figure(figsize = (12, 12))\n",
    "sns.heatmap(corrs, annot = True, vmin = -1, vmax = 1, fmt = '.3f', cmap=plt.cm.PiYG_r);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upgraded Model\n",
    "\n",
    "When we want to improve performance, we generally have a few options:\n",
    "\n",
    "1. Get more data - either more observations or more variables\n",
    "2. Engineer more / better features\n",
    "3. Perform feature selection to remove irrelevant features\n",
    "4. Try a more complex model\n",
    "5. Perform hyperparameter tuning of the selected model\n",
    "\n",
    "We already saw that including another feature could improve perfomance. For now let's move past the features and focus on the model (we'll come back to features later).\n",
    "\n",
    "The simple linear regression has no hyperparameters to optimize (no settings to tune) so we'll try approach 4. If the more complex model does well, we can use it for testing additional features or performing feature selection\n",
    "\n",
    "## Use Non-Linear Model\n",
    "\n",
    "For a first non-linear model, we'll use the Random Forest regressor. This is a powerful ensemble of regression trees that has good performance and generalization ability because of its low variance. We'll use most of the default hyperparameters but change the `n_estimators` and the `max_depth` of each tree in the forest. For the features, we'll use the four features which delivered good performance in the linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Create the random forest\n",
    "random_forest = RandomForestRegressor(n_estimators = 25, max_depth = 25, \n",
    "                                      max_features = None, oob_score = True, \n",
    "                                      bootstrap = True, verbose = 1, n_jobs = -1)\n",
    "\n",
    "# Train on data\n",
    "random_forest.fit(X_train[['haversine', 'abs_lat_diff', 'abs_lon_diff', 'passenger_count']], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(random_forest, ['haversine', 'abs_lat_diff', 'abs_lon_diff', 'passenger_count'],\n",
    "         X_train, X_valid, y_train, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest does much better than the simple linear regression. This indicates that the problem is probably not linear, or at least is not linear in terms of the features we have constructed. From here going forward, we'll use the same random forest model because of the increased performance. \n",
    "\n",
    "#### Overfitting\n",
    "\n",
    "Given the gap between the training and the validation score, we can see that our model is __overfitting__ to the training. This is one of the most common problems in machine learning and is usually addressed either by training with more data, or adjusting the hyperparameters of the model. This leads to another recommendation for improvement:\n",
    "\n",
    "* __Potential Improvement 4: Try searching for better random forest model hyperparameters__. You may find Scikit-Learn's `RandomizedSearchCV` a useful tool.\n",
    "\n",
    "Next we can make predictions with the random forest for uploading to the competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = random_forest.predict(test[['haversine', 'abs_lat_diff', 'abs_lon_diff', 'passenger_count']])\n",
    "\n",
    "sub = pd.DataFrame({'key': test_id, 'fare_amount': preds})\n",
    "sub.to_csv('sub_rf_simple.csv', index = False)\n",
    "\n",
    "sns.distplot(sub['fare_amount'])\n",
    "plt.title('Distribution of Random Forest Predictions');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we don't see any extreme predictions as we saw with the first linear regression. The random forest tends to not produce outlying predictions because the voting of the trees means that any single tree that estimates an extreme value will be tempered by the other predictions. \n",
    "\n",
    "Let's look at the 3 predictions the original simple linear regression estimated as over \\$100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.loc[simple_over_100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Features\n",
    "\n",
    "Now that we've decided on the Random Forest as our model, we can try using additional features. Let's see what happens when we use 8 of the features for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_rf(X_train, X_valid, y_train, y_valid, test, features,\n",
    "             model = RandomForestRegressor(n_estimators = 25, max_depth = 25,\n",
    "                                           n_jobs = -1)):\n",
    "    \n",
    "    # Train\n",
    "    model.fit(X_train[features], y_train)\n",
    "    \n",
    "    # Validation\n",
    "    evaluate(model, features, X_train, X_valid, y_train, y_valid)\n",
    "    \n",
    "    # Make predictions on test and generate submission dataframe\n",
    "    preds = model.predict(test[features])\n",
    "    sub = pd.DataFrame({'key': test_id, 'fare_amount': preds})\n",
    "    \n",
    "    # Extract feature importances\n",
    "    feature_importances = pd.DataFrame({'feature': features,\n",
    "                                        'importance': model.feature_importances_}).\\\n",
    "                           sort_values('importance', ascending = False)\n",
    "    \n",
    "    return sub, feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate using 8 features\n",
    "sub, fi = model_rf(X_train, X_valid, y_train, y_valid, test, \n",
    "                   features = ['abs_lat_diff', 'abs_lon_diff', 'haversine', 'passenger_count',\n",
    "                               'pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that using more features helps the model! We can look at the feature importances to see which the model considers \"most relevant\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `haversine` distance is by far the most important with the other features showing considerably less relevance to the model. This suggests that distance is key, and we might want to find a more accurate way of calculating distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('sub_rf_8_features.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Feature Engineering\n",
    "\n",
    "We saw that adding more features improves the performance of the model. A natural progression is therefore to use even more features! We have not made any use of the `pickup_datetime` which provides the precise moment of pickup and that's where we'll turn our attention to next. \n",
    "\n",
    "## Extract Datetime Information\n",
    "\n",
    "We can write a simple function that extracts as much date and time information from a datetime as possible. This is adapted from the excellent fast.ai library, in particular, the structured module (available at https://github.com/fastai/fastai/blob/master/fastai/structured.py). I have made a few changes based on what's worked best for me in the past on time-series problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function calculates a number of expected attributes:\n",
    "\n",
    "* Year\n",
    "* Month\n",
    "* Day\n",
    "* Day of Year\n",
    "* Day of Week\n",
    "\n",
    "When we have a time, additional variables can be calculated:\n",
    "\n",
    "* Hour \n",
    "* Minute \n",
    "* Second\n",
    "\n",
    "Pandas also offers options for some more complex attributes like:\n",
    "\n",
    "* Is_month_end  \n",
    "* Is_month_start\n",
    "* Is_quarter_end\n",
    "* Is_quarter_start\n",
    "* Is_year_end\n",
    "* Is_year_start\n",
    "\n",
    "These are more intended for financial analysis, but they may come in handy in other problems. For now, I have decided not to use these attributes.\n",
    "\n",
    "### Fractional Time Variables\n",
    "\n",
    "Finally, I add a number of other calculations that combine existing measures to create fractional variables:\n",
    "\n",
    "* Fractional time of day\n",
    "* Fractional time of week\n",
    "* Fractional time of month\n",
    "* Fractional time of year\n",
    "\n",
    "These are all measured from 0 - 1 in units of whichever time period we are measuring on. The idea behind these variables is that they can take the place of several other time indicators. For example, instead of using the `Dayof week`, `Hour`, `Minute`, and `Second`, we can use the fractional time of the week to find out precisely when the observation takes place in the week.\n",
    "\n",
    "I have found that the fractional time variables work well in practice especially with non-linear models. When we use linear models, a good approach is [cyclical variable encoding](https://ianlondon.github.io/blog/encoding-cyclical-features-24hour-time/) of time features, but I haven't found this to be necessary with non-linear models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rounded = data.round(2).groupby(['pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude'])['fare_amount'].count().reset_index().drop(columns = 'fare_amount')\n",
    "data_rounded.to_csv('input/data_rounded.csv', index = False)\n",
    "data_rounded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rounded = test.round(2).groupby(['pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude'])['haversine'].count().reset_index().drop(columns = 'haversine')\n",
    "test_rounded.to_csv('input/test_rounded.csv', index = False)\n",
    "test_rounded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_dateinfo(df, date_col, drop=True, time=False, \n",
    "                     start_ref = pd.datetime(1900, 1, 1),\n",
    "                     extra_attr = False):\n",
    "    \"\"\"\n",
    "    Extract Date Information from a DataFrame\n",
    "    Adapted from: https://github.com/fastai/fastai/blob/master/fastai/structured.py\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Extract the field\n",
    "    fld = df[date_col]\n",
    "    \n",
    "    # Check the time\n",
    "    fld_dtype = fld.dtype\n",
    "    if isinstance(fld_dtype, pd.core.dtypes.dtypes.DatetimeTZDtype):\n",
    "        fld_dtype = np.datetime64\n",
    "\n",
    "    # Convert to datetime if not already\n",
    "    if not np.issubdtype(fld_dtype, np.datetime64):\n",
    "        df[date_col] = fld = pd.to_datetime(fld, infer_datetime_format=True)\n",
    "    \n",
    "\n",
    "    # Prefix for new columns\n",
    "    pre = re.sub('[Dd]ate', '', date_col)\n",
    "    pre = re.sub('[Tt]ime', '', pre)\n",
    "    \n",
    "    # Basic attributes\n",
    "    attr = ['Year', 'Month', 'Week', 'Day', 'Dayofweek', 'Dayofyear', 'Days_in_month', 'is_leap_year']\n",
    "    \n",
    "    # Additional attributes\n",
    "    if extra_attr:\n",
    "        attr = attr + ['Is_month_end', 'Is_month_start', 'Is_quarter_end', \n",
    "                       'Is_quarter_start', 'Is_year_end', 'Is_year_start']\n",
    "    \n",
    "    # If time is specified, extract time information\n",
    "    if time: \n",
    "        attr = attr + ['Hour', 'Minute', 'Second']\n",
    "        \n",
    "    # Iterate through each attribute\n",
    "    for n in attr: \n",
    "        df[pre + n] = getattr(fld.dt, n.lower())\n",
    "        \n",
    "    # Calculate days in year\n",
    "    df[pre + 'Days_in_year'] = df[pre + 'is_leap_year'] + 365\n",
    "        \n",
    "    if time:\n",
    "        # Add fractional time of day (0 - 1) units of day\n",
    "        df[pre + 'frac_day'] = ((df[pre + 'Hour']) + (df[pre + 'Minute'] / 60) + (df[pre + 'Second'] / 60 / 60)) / 24\n",
    "        \n",
    "        # Add fractional time of week (0 - 1) units of week\n",
    "        df[pre + 'frac_week'] = (df[pre + 'Dayofweek'] + df[pre + 'frac_day']) / 7\n",
    "    \n",
    "        # Add fractional time of month (0 - 1) units of month\n",
    "        df[pre + 'frac_month'] = (df[pre + 'Day'] + (df[pre + 'frac_day'])) / (df[pre + 'Days_in_month'] +  1)\n",
    "        \n",
    "        # Add fractional time of year (0 - 1) units of year\n",
    "        df[pre + 'frac_year'] = (df[pre + 'Dayofyear'] + df[pre + 'frac_day']) / (df[pre + 'Days_in_year'] + 1)\n",
    "        \n",
    "    # Add seconds since start of reference\n",
    "    df[pre + 'Elapsed'] = (fld - start_ref).dt.total_seconds()\n",
    "    \n",
    "    if drop: \n",
    "        df = df.drop(date_col, axis=1)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['pickup_datetime'] = pd.to_datetime(data['pickup_datetime'])\n",
    "# test['pickup_datetime'] = pd.to_datetime(test['pickup_datetime'])\n",
    "\n",
    "# print(data['pickup_datetime'].min())\n",
    "# print(test['pickup_datetime'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = extract_dateinfo(test, 'pickup_datetime', drop = False, \n",
    "                         time = True, start_ref = data['pickup_datetime'].min())\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = extract_dateinfo(data, 'pickup_datetime', drop = False, \n",
    "                         time = True, start_ref = data['pickup_datetime'].min())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Time Variables\n",
    "\n",
    "We now have a ton of time-variables to explore! First, let's ask the question if fares have increased over time. To do this, we can plot the `time_elapsed` versus the fare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 8))\n",
    "sns.regplot('pickup_Elapsed', 'fare_amount', scatter_kws= {'alpha': 0.05}, marker = '.',\n",
    "           data = data.sample(100000, random_state=RSEED));\n",
    "plt.title('Fare Amount versus Time Since Start of Records');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There appears to be a minor increase in prices over time which might be expected taking into account inflation. Let's look at the average fare amount by the hour of day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 8))\n",
    "for h, grouped in data.groupby('pickup_Hour'):\n",
    "    sns.kdeplot(grouped['fare_amount'], label = f'{h} hour')\n",
    "plt.title('Fare Amount by Hour of Day');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make the same plot by day of the week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 8))\n",
    "for d, grouped in data.groupby('pickup_Dayofweek'):\n",
    "    sns.kdeplot(grouped['fare_amount'], label = f'{d}')\n",
    "plt.title('Fare Amount by Day of Week');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both of these plots do not seem to show much difference between the different times. \n",
    "\n",
    "### Fractional Time Plots\n",
    "\n",
    "As a final exploration of the time variables, we can plot the fare amount versus the fractional time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize = (16, 16))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot each of the fractional times\n",
    "for i, d in enumerate(['day', 'week', 'month', 'year']):\n",
    "    ax = axes[i]\n",
    "    sns.regplot(f'pickup_frac_{d}', 'fare_amount', \n",
    "                data = data.sample(100000, random_state = RSEED), \n",
    "                fit_reg = False, scatter_kws = {'alpha': 0.05}, marker = '.', ax = ax,\n",
    "                color = 'r')\n",
    "    \n",
    "    ax.set_title(f'Fare Amount vs pickup_frac_{d}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of these graphs are very decisive. One interesting thing to note is the horizontal bars at different fare amounts. This suggests there may be certain routes that always have the same fare amount. We explored the fare distribution earlier, but it might be a good idea to revisit the abnormalities in the fares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fare_counts = data.groupby('fare_amount')['haversine'].agg(['count', pd.Series.nunique]).sort_values('count', ascending = False)\n",
    "fare_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of very common fares. These could indicate certain rides that are a set amount. This brings up another area for improvement: \n",
    "\n",
    "* __Potential improvement 5: find out what the same amount fares have in common.__ See if this can be used to determine if there are standard fares, and what these rides are which could be used for modeling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Time Features\n",
    "\n",
    "Now we can use the time features in our model to see if they yield any improvement. We'll need to resplit the data (using the same random state)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(data, np.array(data['fare_amount']), \n",
    "                                                      stratify = data['fare-bin'],\n",
    "                                                      random_state = RSEED, test_size = 1_000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the time features, we'll use the fractional measurements as well as the time elapsed since the beginning of the records. We'll keep the same features as the previous training run except remove the passenger count since it was the lowest importance feature in the random forest. (This gives us a total of 12 features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_features = ['pickup_frac_day', 'pickup_frac_week', 'pickup_frac_month', 'pickup_frac_year',\n",
    "                 'pickup_Elapsed']\n",
    "\n",
    "features = ['abs_lat_diff', 'abs_lon_diff', 'haversine', \n",
    "            'pickup_latitude', 'pickup_longitude', \n",
    "            'dropoff_latitude', 'dropoff_longitude'] + time_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test using the 7 features and the time features\n",
    "sub, fi = model_rf(X_train, X_valid, y_train, y_valid, test, \n",
    "                   features = features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for comparison, we can go back to the linear regression and look at the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "\n",
    "# Fit and evaluate\n",
    "lr.fit(X_train[features], y_train)\n",
    "evaluate(lr, features, X_train, X_valid, y_train, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the new features helped both the random forest and the linear regression. Let's take a look at the random forest feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fi.set_index('feature', inplace = True)\n",
    "plt.figure(figsize = (10, 8))\n",
    "fi['importance'].plot.bar(color = 'g', edgecolor = 'k');\n",
    "plt.ylabel('Importance'); plt.title('Feature Importances');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, the `haversine` distance dominates the importance. The time elapsed since the first record seems to be relatively important although the other time features do not seem to be of much use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save submission\n",
    "sub.to_csv('sub_rf_frac_time.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try with All Time Variables\n",
    "\n",
    "For a final submission, we'll use every single one of the features. This probably will lead to overfitting, but let's test it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(data.columns)\n",
    "\n",
    "for f in ['pickup_datetime', 'fare_amount', 'fare-bin']:\n",
    "    features.remove(f)\n",
    "    \n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test using the 7 features and the time features\n",
    "sub, fi = model_rf(X_train, X_valid, y_train, y_valid, test, \n",
    "                   features = features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi.set_index('feature', inplace = True)\n",
    "plt.figure(figsize = (12, 7))\n",
    "fi['importance'].plot.bar(color = 'g', edgecolor = 'k');\n",
    "plt.ylabel('Importance'); plt.title('Feature Importances');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('sub_rf_all_features.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better Model\n",
    "\n",
    "Although the random forest has high performance, it does not always work the best for every problem. There are still more models to try:\n",
    "\n",
    "* __Potential improvement 6: try more models.__ You might find the Gradient Boosting Machine or Deep Neural Networks to be capable learners.\n",
    "\n",
    "# Your Challenge\n",
    "\n",
    "From here, we can still engineer more features or we can try upgrading the model. At this point, I'm going to leave it up to you! I've given you a decent start and some recommendations for improvement so I'll leave you here. I'm working on some more notebooks with additional performance gains, but see if you can take these methods and improve! To wrap up, here are my recommendations:\n",
    "\n",
    "1. Train with more data\n",
    "2. Find a better way for filtering outliers\n",
    "3. Find an optimal set of features\n",
    "4. Hyperparameter tuning of the random forest\n",
    "5. Use domain knowledge to figure out if there are standard fares or what the same fares have in common\n",
    "6. Try more complex models\n",
    "\n",
    "I have to add that these are all __potential__ improvements because of course we don't know if they will work until we try! I wish you the best of luck, and I'll be back in another kernel with some improvements of my own. \n",
    "\n",
    "Best,\n",
    "\n",
    "Will"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
